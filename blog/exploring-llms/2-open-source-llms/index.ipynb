{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Part 2: Open Source LLMs\"\n",
        "author: Victor Roussekov\n",
        "date: 2023-09-19\n",
        "date-modified: last-modified\n",
        "categories: [Python, Notebook]\n",
        "\n",
        "share:\n",
        "  permalink: https://victorouse.github.io/blog/exploring-llms/part-two/notebook\n",
        "  description: What he said ðŸ‘‰\n",
        "  twitter: true\n",
        "  reddit: true\n",
        "  linkedin: true\n",
        "  email: true\n",
        "  mastodon: true\n",
        "\n",
        "citation: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HuggingFace\n",
        "\n",
        "Models created by the Open Source community are generally written in Python using frameworks like [PyTorch](https://pytorch.org/) and [Tensorflow](https://www.tensorflow.org/).\n",
        "\n",
        "Each model will have its own instructions on how to compile and run them.\n",
        "\n",
        "One popular library that abstracts the downloading, loading, and API of [compatible] models is the HuggingFace [transformers](https://github.com/huggingface/transformers) library.\n",
        "\n",
        "The `transformers` library is able to download and load any model published on the [HuggingFace Hub](https://huggingface.co/docs/hub/index)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "huggingface-setup"
        ]
      },
      "source": [
        "First, we will need to create a HuggingFace Account and login using the HuggingFace CLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After we've logged in, we now have access to all the `transformers` [models](https://huggingface.co/models?library=transformers&sort=downloads) on HuggingFace.\n",
        "\n",
        "We can now pick a model, and use the `pipeline` function from the `transformers` library to download and load our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "print(classifier('I love cats'))\n",
        "print(classifier('I hate dogs'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that we passed the string argument `sentiment-analysis`, which itself is not actually a model, but a [task](https://huggingface.co/docs/transformers/main/en/task_summary).\n",
        "\n",
        "Tasks in this context refer to common Natrual Language Processing (NLP) tasks, with `sentiment-analysis` being one of them.\n",
        "\n",
        "Each task has it's own string identifier, i.e. `sentiment-analysis` and a default model that is used for the task.\n",
        "\n",
        "This is why we observed the following output from the previous step:\n",
        "\n",
        "```shell\n",
        "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
        "```\n",
        "\n",
        "We can see that the task is using the [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) model downloaded from HuggingFace.\n",
        "\n",
        "We can specify an alternative model, such as the [finiteautomata/bertweet-base-sentiment-analysis](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis) model by providing a `model` argument to the `pipeline` function:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This classifier is trained on Tweets!\n",
        "classifier = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
        "\n",
        "print(classifier('I love Elon Musk'))\n",
        "print(classifier('I hate Elon Musk'))\n",
        "print(classifier('OpenAI is good'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "victorouse--mQ1V7xy-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
