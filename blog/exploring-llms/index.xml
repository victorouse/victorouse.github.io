<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Victor Roussekov</title>
<link>https://victorouse.zip/blog/exploring-llms/index.html</link>
<atom:link href="https://victorouse.zip/blog/exploring-llms/index.xml" rel="self" type="application/rss+xml"/>
<description>Data Engineer at Spaceship. Currently living in Sydney, Australia.</description>
<image>
<url>https://placehold.co/1600x900/f7f7f7/121212.png?text=Exploring+LLMs.&font=playfair-display</url>
<title>Victor Roussekov</title>
<link>https://victorouse.zip/blog/exploring-llms/index.html</link>
</image>
<generator>quarto-1.4.376</generator>
<lastBuildDate>Tue, 19 Sep 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Part 1: Introduction to LLMs</title>
  <dc:creator>Victor Roussekov</dc:creator>
  <link>https://victorouse.zip/blog/exploring-llms/1-introduction-to-llms/index.html</link>
  <description><![CDATA[ 



<hr>
<section id="what-are-large-language-models" class="level3">
<h3 class="anchored" data-anchor-id="what-are-large-language-models">What are Large Language Models?</h3>
<p>Large Language Models (LLMs) are neural networks that can generate output such as text, images, etc. Each model has its own applied methodology, reflected in how the neural network is configured.</p>
<p>To use neural networks, they must first be “trained”. The training process involves passing “training” data through the network and evaluating the output against a “validation” or “testing” set.</p>
<p>This process adjusts the model “weights” along the way, and once the training process is finished, the resulting weights can be distributed for use.</p>
<p>The resulting weights are generally referred to as “pre-trained” models that are distributed in a format that can be “loaded” into a model.</p>
<p>There are many different types of models, from OpenAI’s proprietary GPT models (GPT3, GTP3.5, GTP4), to open source models like Meta’s <a href="https://ai.meta.com/llama/">Llama2</a>.</p>
<p>There are many open sources models that can be downloaded from a model artefact repository called <a href="https://huggingface.co/">HuggingFace</a>. You can think of HuggingFace like the DockerHub for LLMs.</p>
<p>There are also platforms that offer LLM hosting services, such as <a href="https://replicate.com/">Replicate</a>, which host these LLM models on the cloud for you, meaning you don’t have to run them on your own hardware.</p>
<p>It is still possible to run LLMs on consumer hardware, and a MacBook should be able to at least run small-to-medium sized models within reasonable timeframes.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{roussekov2023,
  author = {Roussekov, Victor},
  title = {Part 1: {Introduction} to {LLMs}},
  pages = {undefined},
  date = {2023-09-19},
  url = {https://victorouse.zip/blog/exploring-llms/1-introduction-to-llms},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-roussekov2023" class="csl-entry quarto-appendix-citeas">
Roussekov, Victor. 2023. <span>“Part 1: Introduction to LLMs.”</span>
September 19, 2023. <a href="https://victorouse.zip/blog/exploring-llms/1-introduction-to-llms">https://victorouse.zip/blog/exploring-llms/1-introduction-to-llms</a>.
</div></div></section></div> ]]></description>
  <category>LLMs</category>
  <category>Exploring LLMs</category>
  <category>Notebook</category>
  <guid>https://victorouse.zip/blog/exploring-llms/1-introduction-to-llms/index.html</guid>
  <pubDate>Tue, 19 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://placehold.co/1600x900/f7f7f7/121212.png?text=Introduction+to+LLMs.&amp;font=playfair-display" medium="image"/>
</item>
<item>
  <title>Part 2: Open Source LLMs</title>
  <dc:creator>Victor Roussekov</dc:creator>
  <link>https://victorouse.zip/blog/exploring-llms/2-open-source-llms/index.html</link>
  <description><![CDATA[ 



<hr>
<section id="huggingface" class="level3">
<h3 class="anchored" data-anchor-id="huggingface">HuggingFace</h3>
<p>Models created by the Open Source community are generally written in Python using frameworks like <a href="https://pytorch.org/">PyTorch</a> and <a href="https://www.tensorflow.org/">Tensorflow</a>.</p>
<p>Each model will have its own instructions on how to compile and run them.</p>
<p>One popular library that abstracts the downloading, loading, and API of [compatible] models is the HuggingFace <a href="https://github.com/huggingface/transformers">transformers</a> library.</p>
<p>The <code>transformers</code> library is able to download and load any model published on the <a href="https://huggingface.co/docs/hub/index">HuggingFace Hub</a>.</p>
<p>First, we will need to create a HuggingFace Account and login using the HuggingFace CLI.</p>
<div id="cell-4" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>pip install huggingface_hub</span></code></pre></div>
</div>
<div id="cell-5" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>huggingface<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>cli login</span></code></pre></div>
</div>
<p>After we’ve logged in, we now have access to all the <code>transformers</code> <a href="https://huggingface.co/models?library=transformers&amp;sort=downloads">models</a> on HuggingFace.</p>
<p>We can now pick a model, and use the <code>pipeline</code> function from the <code>transformers</code> library to download and load our model.</p>
<div id="cell-7" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>pip install transformers</span></code></pre></div>
</div>
<div id="cell-8" class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pipeline</span>
<span id="cb4-2"></span>
<span id="cb4-3">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sentiment-analysis'</span>)</span>
<span id="cb4-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'I love cats'</span>))</span>
<span id="cb4-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'I hate dogs'</span>))</span></code></pre></div>
</div>
<p>Note that we passed the string argument <code>sentiment-analysis</code>, which itself is not actually a model, but a <a href="https://huggingface.co/docs/transformers/main/en/task_summary">task</a>.</p>
<p>Tasks in this context refer to common Natrual Language Processing (NLP) tasks, with <code>sentiment-analysis</code> being one of them.</p>
<p>Each task has it’s own string identifier, i.e.&nbsp;<code>sentiment-analysis</code> and a default model that is used for the task.</p>
<p>This is why we observed the following output from the previous step:</p>
<pre class="shell"><code>No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).</code></pre>
<p>We can see that the task is using the <a href="https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english">distilbert-base-uncased-finetuned-sst-2-english</a> model downloaded from HuggingFace.</p>
<p>We can specify an alternative model, such as the <a href="https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis">finiteautomata/bertweet-base-sentiment-analysis</a> model by providing a <code>model</code> argument to the <code>pipeline</code> function:</p>
<hr>
<div id="cell-11" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>pip install emoji</span></code></pre></div>
</div>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This classifier is trained on Tweets!</span></span>
<span id="cb7-2">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"finiteautomata/bertweet-base-sentiment-analysis"</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'I love Elon Musk'</span>))</span>
<span id="cb7-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'I hate Elon Musk'</span>))</span>
<span id="cb7-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'OpenAI is good'</span>))</span></code></pre></div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{roussekov2023,
  author = {Roussekov, Victor},
  title = {Part 2: {Open} {Source} {LLMs}},
  pages = {undefined},
  date = {2023-09-19},
  url = {https://victorouse.zip/blog/exploring-llms/2-open-source-llms},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-roussekov2023" class="csl-entry quarto-appendix-citeas">
Roussekov, Victor. 2023. <span>“Part 2: Open Source LLMs.”</span>
September 19, 2023. <a href="https://victorouse.zip/blog/exploring-llms/2-open-source-llms">https://victorouse.zip/blog/exploring-llms/2-open-source-llms</a>.
</div></div></section></div> ]]></description>
  <category>Python</category>
  <category>Notebook</category>
  <guid>https://victorouse.zip/blog/exploring-llms/2-open-source-llms/index.html</guid>
  <pubDate>Tue, 19 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://placehold.co/1600x900/f7f7f7/121212.png?text=Open+Source+LLMs.&amp;font=playfair-display" medium="image"/>
</item>
</channel>
</rss>
